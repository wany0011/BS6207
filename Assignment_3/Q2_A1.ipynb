{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043b8bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.trial import TrialState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4eaddec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165e78cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ToTensor: Grayscale image (RGB 0)~255 to 0~Normalize to the range of 1), Normalize: Z-value (RGB mean and standard deviation to 0).Normalize with 5)\n",
    "transform = transforms.Compose([transforms.ToTensor()])#, transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "#Download training data\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "\n",
    "#Download test data\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a68bdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training dataset: 50,000 RGB images with 32 pixels in height and width\n",
    "print(train_dataset.data.shape)\n",
    "(50000, 32, 32, 3)\n",
    "\n",
    "#Test dataset: 10000 RGB images with 32 pixels in height and width\n",
    "print(test_dataset.data.shape)\n",
    "(10000, 32, 32, 3)\n",
    "\n",
    "#Check the class list\n",
    "print(train_dataset.classes)\n",
    "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "#Classes are often used, so keep them separately\n",
    "classes = train_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b855e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbebb8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassificationBase(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n",
    "        \n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888878c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement CNN\n",
    "class Cifar10CnnModel(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "        \n",
    "        nn.Conv2d(3, 16, 3,1,1),\n",
    "        nn.ReLU(),    \n",
    "        nn.Conv2d(16, 16, 3,1,1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2, 2),\n",
    "        \n",
    "        nn.Conv2d(16, 32, 3,1,1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(32, 32, 3,1,1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2, 2),\n",
    "            \n",
    "        nn.Conv2d(32, 64, 3,1,1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(64, 64, 3,1,1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2, 2),\n",
    "            \n",
    "        nn.Conv2d(64, 128, 3,1,1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(128, 128, 3,1,1),\n",
    "        nn.ReLU(),\n",
    "        nn.AdaptiveAvgPool2d(1),\n",
    "        \n",
    "        nn.Flatten(),\n",
    "        nn.Linear(128, 10))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "model = Cifar10CnnModel()\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98a71ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "torch.manual_seed(random_seed);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77926d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "val_size = 5000\n",
    "train_size = len(train_dataset) - val_size\n",
    "\n",
    "train_ds, val_ds = random_split(train_dataset, [train_size, val_size])\n",
    "len(train_ds), len(val_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a7ad5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4,pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, shuffle=False,num_workers=4,pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False,num_workers=4,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7202b527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "\n",
    "def show_batch(dl):\n",
    "    for images, labels in dl:\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8af5f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3a6809",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfc1a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1b7564",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c072a115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14dded86",
   "metadata": {},
   "source": [
    "### Test output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c5251e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_loader:\n",
    "    print('images.shape:', images.shape)\n",
    "    out = model(images)\n",
    "    print('out.shape:', out.shape)\n",
    "    print('out[0]:', out[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7133629d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126b0e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DeviceDataLoader(train_loader,device)\n",
    "val_dl = DeviceDataLoader(val_loader,device)\n",
    "test_dl = DeviceDataLoader(test_loader,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2428fc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce045784",
   "metadata": {},
   "source": [
    "# try different scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd22788",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d668a17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = to_device(Cifar10CnnModel(), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0776bb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=evaluate(model, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d294075c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['val_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41c36bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f6e6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "#Cross entropy\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "lr = 0.000859941832304690\n",
    "opt_func = torch.optim.Adam\n",
    "\n",
    "model = to_device(Cifar10CnnModel(), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ba2db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 62\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4,pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, shuffle=False,num_workers=4,pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False,num_workers=4,pin_memory=True)\n",
    "\n",
    "train_dl = DeviceDataLoader(train_loader,device)\n",
    "val_dl = DeviceDataLoader(val_loader,device)\n",
    "test_dl = DeviceDataLoader(test_loader,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abb7061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    \n",
    "    model = to_device(Cifar10CnnModel(), device)\n",
    "    \n",
    "    history = []\n",
    "    lrs = []\n",
    "    optimizer = opt_func(model.parameters(), lr,weight_decay=1e-4)\n",
    "    #scheduler = ReduceLROnPlateau(optimizer, 'min')\n",
    "    \n",
    "    #scheduler_2 = ReduceLROnPlateau(optimizer)\n",
    "    for epoch in range(epochs):     \n",
    "        torch.manual_seed(np.random.randint(5000));\n",
    "        train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4,pin_memory=True)\n",
    "        train_dl = DeviceDataLoader(train_loader,device)\n",
    "        \n",
    "        # Training Phase \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch in train_dl:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()       \n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        result = evaluate(model, val_dl)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "        \n",
    "        #scheduler.step(result['val_loss'])\n",
    "        #print(result['val_loss'])\n",
    "        \n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "        \n",
    "    #torch.optim.swa_utils.update_bn(loader, swa_model)\n",
    "    # Use swa_model to make predictions on test data\n",
    "    #preds = swa_model(test_input)    \n",
    "    return history,lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41626b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "history,lrs = fit(num_epochs, lr, model, train_ds, val_dl, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82444c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_default_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b287ccd",
   "metadata": {},
   "source": [
    "# Try \"Optuna\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a586bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS =20\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "def objective(trial):    \n",
    "    # Generate the model.\n",
    "    model = to_device(Cifar10CnnModel(), device)\n",
    "        \n",
    "    lr = trial.suggest_float(\"lr\", 1e-6, 1e-2, log=True)\n",
    "    batch_size = trial.suggest_int(\"batch_size\",16,1024) \n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4,pin_memory=True)\n",
    "    valid_loader = DataLoader(val_ds, shuffle=False,num_workers=4,pin_memory=True)\n",
    "    \n",
    "    \n",
    "    train_dl = DeviceDataLoader(train_loader,device)\n",
    "    val_dl = DeviceDataLoader(valid_loader,device)\n",
    "    \n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr)\n",
    "    \n",
    " # Training of the model.\n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        torch.manual_seed(np.random.randint(5000));\n",
    "        train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4,pin_memory=True)\n",
    "        train_dl = DeviceDataLoader(train_loader,device)\n",
    "        \n",
    "        model.train()\n",
    "            \n",
    "        for idx,batch in enumerate(train_dl):\n",
    "            loss = model.training_step(batch)\n",
    "            #train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()       \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            #if idx>30:\n",
    "            #    break\n",
    "            \n",
    "\n",
    "        # Validation of the model.\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            outputs = [model.validation_step(batch) for batch in val_dl]\n",
    "            result=model.validation_epoch_end(outputs)\n",
    "            \n",
    "        print(\"epoch=%d, accuracy=%f\"%(epoch,result['val_acc'])) \n",
    "        trial.report(result['val_acc'],epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "    return result['val_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d852e733",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=500, timeout=72000)\n",
    "\n",
    "    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "    print(\"Study statistics: \")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc8ea02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
