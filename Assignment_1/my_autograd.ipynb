{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12f85eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7736a597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "492e3b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of hidden layers\n",
    "K=10\n",
    "# number of input nodes\n",
    "d=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "455f66b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 1, d, [2*d+1,K], 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6e02b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=1e-4\n",
    "epoches=10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50aa9716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x16e48db5a90>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e7eaac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.rand(1,D_in)\n",
    "y_train= torch.mean(x_train*x_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "72f4c56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4869, 0.1052, 0.5883, 0.1161, 0.4949, 0.2824, 0.5899, 0.8105, 0.2512,\n",
      "         0.6307]])\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36ac2805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2398)\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c3bae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Q1NN:\n",
    "    def __init__(self,N, D_in, H, D_out ):\n",
    "        \n",
    "        # nn_architecture \n",
    "        \n",
    "        # parameters\n",
    "        self.batchSize=N\n",
    "        self.inputSize = D_in \n",
    "        self.hiddenLayer = H\n",
    "        self.outputSize = D_out\n",
    "        \n",
    "        # weights & bias\n",
    "        # dictionary of parameters\n",
    "        self.layers=[]   \n",
    "        \n",
    "        \"\"\"\n",
    "        weight=torch.rand((D_in, H[0]), dtype=torch.float)\n",
    "        bias=torch.rand(H[0],dtype=torch.float)\n",
    "        output=torch.rand(H[0],dtype=torch.float)\n",
    "        dw = torch.zeros((D_in, H[0]), dtype=torch.float)\n",
    "        db =torch.zeros(H[0],dtype=torch.float)\n",
    "        self.layers.append({\"weight\":weight,\"bias\":bias,\"output\":output,\"dw\":dw,\"db\":db})\n",
    "        \"\"\"\n",
    "        \n",
    "        for ii in range(0, H[1]):\n",
    "            \n",
    "            # input dimention of the 1st layer\n",
    "            tmp_in = D_in  if ii == 0 else H[0]\n",
    "            # output dimention of the last layer\n",
    "            tmp_out= D_out if ii == H[1]-1 else H[0]\n",
    "        \n",
    "            # option _1 : weights and bias \n",
    "            #weight=torch.zeros((tmp_in, tmp_out), dtype=torch.float)\n",
    "            #bias=torch.ones(tmp_out,dtype=torch.float)\n",
    "            \n",
    "            # option _2 : weights and bias\n",
    "            weight=torch.rand((tmp_in, tmp_out), dtype=torch.float)\n",
    "            bias=torch.rand(tmp_out,dtype=torch.float)\n",
    "            \n",
    "            \n",
    "            #print(\"weight={}\".format(weight))\n",
    "            #print(\"bias={}\".format(bias))\n",
    "            \n",
    "            # output of that neuron\n",
    "            ll = torch.zeros(tmp_out,dtype=torch.float)\n",
    "            output= torch.zeros(tmp_out,dtype=torch.float)\n",
    "            # \n",
    "            dw = torch.zeros((tmp_in, tmp_out), dtype=torch.float)\n",
    "            db = torch.zeros(tmp_out,dtype=torch.float) \n",
    "            self.layers.append({\"weight\":weight,\"bias\":bias,\"ll\":ll,\"output\":output,\"dw\":dw,\"db\":db})\n",
    "        \n",
    "        \"\"\"\n",
    "        # the Last Layer\n",
    "        weight=torch.rand((H[0], D_out), dtype=torch.float)\n",
    "        bias=torch.rand(D_out,dtype=torch.float)\n",
    "        output=torch.rand(D_out,dtype=torch.float)\n",
    "        # \n",
    "        dw = torch.zeros((H[0], D_out), dtype=torch.float)\n",
    "        db = torch.zeros(D_out,dtype=torch.float) \n",
    "        self.layers.append({\"weight\":weight,\"bias\":bias,\"output\":output,\"dw\":dw,\"db\":db})        \n",
    "        \"\"\"\n",
    "    def relu(self,s):\n",
    "        tmp_zeros = torch.zeros(s.size())\n",
    "        return torch.max(tmp_zeros, s)\n",
    "    \n",
    "    def reluPrime(self,s):\n",
    "        tmp_zeros = torch.zeros(s.size())\n",
    "        tmp_ones = torch.ones(s.size())\n",
    "        s=torch.where(s > 0, tmp_ones, tmp_zeros)\n",
    "        return s    \n",
    "                \n",
    "    def forward(self, X):\n",
    "        temp=X\n",
    "        for ii in range (0,H[1]):\n",
    "            #print(\"=> layer: %d\"%ii)\n",
    "            #print(X)\n",
    "            #print(self.layers[ii][\"weight\"])\n",
    "            #print(self.layers[ii][\"bias\"])\n",
    "            a=torch.matmul(temp, self.layers[ii][\"weight\"])+self.layers[ii][\"bias\"]\n",
    "            self.layers[ii][\"ll\"]=a\n",
    "            z=self.relu(a)\n",
    "            self.layers[ii][\"output\"]=z\n",
    "            temp=z\n",
    "        return z\n",
    "                    \n",
    "    \n",
    "    def backward(self,yhat,y,x):\n",
    "                \n",
    "        #m = D_out    \n",
    "        dz = 2*torch.mean((yhat-y))\n",
    "        \n",
    "        for ii in range (H[1]-1,-1,-1):            \n",
    "            if ii==H[1]-1:\n",
    "                dz= dz*self.reluPrime(self.layers[ii][\"ll\"])\n",
    "                self.layers[ii][\"dw\"] =torch.mm(self.layers[ii-1][\"output\"].T , dz )\n",
    "                #self.layers[ii][\"db\"] =dz  \n",
    "                                \n",
    "            if ii<H[1]-1 and ii>0 :\n",
    "                dz= torch.mm(dz,self.layers[ii+1][\"weight\"].T) * self.reluPrime(self.layers[ii][\"ll\"])\n",
    "                self.layers[ii][\"dw\"]= torch.mm(self.layers[ii-1][\"output\"].T, dz)\n",
    "                #self.layers[ii][\"db\"] =dz\n",
    "                \n",
    "            if ii==0:\n",
    "                dz= torch.mm(dz,self.layers[ii+1][\"weight\"].T) * self.reluPrime(self.layers[ii][\"ll\"])\n",
    "                self.layers[ii][\"dw\"]= torch.mm(x.T, dz)\n",
    "                #self.layers[ii][\"db\"] =dz.squeeze()\n",
    "            \n",
    "            #print(\"dz.size={}\".format(dz.size()))\n",
    "            #print(\"dz(squeeze).size={}\".format(dz.squeeze().size()))\n",
    "            self.layers[ii][\"db\"]=dz.squeeze()\n",
    "            \n",
    "            #print(\"layer{}(weight) gradient:{}\".format(ii,self.layers[ii][\"dw\"]))\n",
    "            #print(\"layer{}(bias) gradient:{}\".format(ii,self.layers[ii][\"db\"]))\n",
    "\n",
    "    \n",
    "    def training(self,x,y,epoches,learning_rate):\n",
    "        lost_list=[]\n",
    "        for e in range (epoches):\n",
    "            #x = torch.rand(N, D_in)\n",
    "            #y=torch.mean(x*x/D_in)\n",
    "            yhat= self.forward(x)\n",
    "            lost=torch.square(yhat-y)\n",
    "            #print(lost)\n",
    "            lost_list.append(lost)\n",
    "            #y = torch.sum(x*x)/D_in\n",
    "            #print(lost)\n",
    "            self.backward(yhat,y,x)                 \n",
    "            \n",
    "            for layer in self.layers:\n",
    "                layer[\"weight\"]-=learning_rate*layer[\"dw\"]\n",
    "                layer[\"bias\"]-=learning_rate*layer[\"db\"]\n",
    "                \n",
    "               \n",
    "            if True:#e==0:\n",
    "                file_name='my_autograd_epoch_'+str(e)+'.dat'\n",
    "                if os.path.exists(file_name):\n",
    "                    os.remove(file_name) #this deletes the file\n",
    "                    \n",
    "                original_stdout = sys.stdout # Save a reference to the original standard output\n",
    "                with open(file_name, 'w') as f:\n",
    "                    sys.stdout = f # Change the standard output to the file we created.    \n",
    "                    \n",
    "                    index=0\n",
    "                    for layer in self.layers:\n",
    "                        print(\"[Layer %d]\"%index)\n",
    "                        #print(\"weight:{}\".format(list(layer[\"dw\"])))  \n",
    "                        #print(\"bias:{}\".format(list(layer[\"db\"])))\n",
    "                        print(layer[\"dw\"])\n",
    "                        print(layer[\"db\"])\n",
    "                        index+=1\n",
    "                    \n",
    "                f.close()    \n",
    "                sys.stdout = original_stdout # Reset the standard output to its original value \n",
    "             \n",
    "        #print(lost_list)        \n",
    "        return(lost_list)\n",
    "        \n",
    "    \n",
    "    def printLayers(self):\n",
    "        index=0\n",
    "        for ii in self.layers:\n",
    "            print(\"# layer {}: {} \".format(index,list(ii[\"weight\"].size())))\n",
    "            index+=1            \n",
    "\n",
    "myNN = Q1NN(N, D_in, H, D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3d88be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# layer 0: [10, 21] \n",
      "# layer 1: [21, 21] \n",
      "# layer 2: [21, 21] \n",
      "# layer 3: [21, 21] \n",
      "# layer 4: [21, 21] \n",
      "# layer 5: [21, 21] \n",
      "# layer 6: [21, 21] \n",
      "# layer 7: [21, 21] \n",
      "# layer 8: [21, 21] \n",
      "# layer 9: [21, 1] \n"
     ]
    }
   ],
   "source": [
    "myNN.printLayers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27eb78b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "49163aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = myNN.training(x_train,y_train,epoches,learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e87f8327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch # 0 lost: 19422226391825907712.00000\n",
      "epoch # 1 lost: 0.05752\n",
      "epoch # 2 lost: 0.05752\n",
      "epoch # 3 lost: 0.05752\n",
      "epoch # 4 lost: 0.05752\n",
      "epoch # 5 lost: 0.05752\n",
      "epoch # 6 lost: 0.05752\n",
      "epoch # 7 lost: 0.05752\n",
      "epoch # 8 lost: 0.05752\n",
      "epoch # 9 lost: 0.05752\n"
     ]
    }
   ],
   "source": [
    "for ii in range(epoches):\n",
    "    print(\"epoch # {} lost: {:.5f}\".format(ii,costs[ii].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90683155",
   "metadata": {},
   "outputs": [],
   "source": [
    "costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939a98f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1919057a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
